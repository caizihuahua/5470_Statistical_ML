{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 94 firm characteristics dataset\n",
    "\n",
    "data_ch = pd.read_csv('../GKX/GKX_20201231.csv')\n",
    "data_ch['DATE'] = pd.to_datetime(data_ch['DATE'], format='%Y%m%d') + pd.offsets.MonthEnd(0)\n",
    "data_ch = data_ch[(data_ch['DATE'] >= '1957-01-31') & (data_ch['DATE'] <= '2016-12-31')]\n",
    "cols = data_ch.columns.tolist()\n",
    "cols_new = [x for x in cols if x not in ['permno', 'prc', 'SHROUT', 'mve0']]\n",
    "data_ch = data_ch[cols_new]\n",
    "data_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dummy variables\n",
    "\n",
    "print(data_ch['sic2'].isnull().sum())\n",
    "data_ch  = data_ch.dropna(subset=['sic2']).reset_index(drop=True)\n",
    "#print(data_ch['sic2'].isnull().sum())\n",
    "\n",
    "dummies = pd.get_dummies(data_ch['sic2'], prefix='dum_')\n",
    "data_ch = data_ch.drop('sic2', axis=1)\n",
    "data_ch = pd.concat([data_ch, dummies], axis=1)\n",
    "print(data_ch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing characteristics\n",
    "\n",
    "chas = [x for x in cols_new if x not in ['DATE', 'RET', 'sic2']]\n",
    "#print(chas)\n",
    "print('Total number of missing characteristics: %d' % (data_ch[chas].isnull().sum().sum()))\n",
    "\n",
    "for cha in chas:\n",
    "    data_ch[cha] = data_ch.groupby('DATE')[cha].transform(lambda x: x.fillna(x.median()))\n",
    "print('Total number of missing characteristics: %d' % (data_ch[chas].isnull().sum().sum()))\n",
    "\n",
    "for cha in chas:\n",
    "    data_ch[cha] = data_ch[cha].transform(lambda x: x.fillna(x.median()))\n",
    "print('Total number of missing characteristics: %d' % (data_ch[chas].isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 8 macroeconomic predictors\n",
    "\n",
    "data_ma = pd.read_csv('PredictorData2023.csv')\n",
    "data_ma['yyyymm'] = pd.to_datetime(data_ma['yyyymm'], format='%Y%m') + pd.offsets.MonthEnd(0)\n",
    "data_ma = data_ma[(data_ma['yyyymm'] >= '1957-01-31') & (data_ma['yyyymm'] <= '2016-12-31')].reset_index(drop=True)\n",
    "data_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct 8 macroeconomic predictors\n",
    "\n",
    "ma_predictors = ['dp', 'ep', 'bm', 'ntis', 'tbl', 'tms', 'dfy', 'svar']\n",
    "data_ma['Index'] = data_ma['Index'].str.replace(',', '').astype('float64')\n",
    "data_ma['dp'] = np.log(data_ma['D12'] / data_ma['Index'])\n",
    "data_ma['ep'] = np.log(data_ma['E12'] / data_ma['Index'])\n",
    "data_ma.rename(columns={'b/m': 'bm'}, inplace=True)\n",
    "data_ma['tms'] = data_ma['lty'] - data_ma['tbl']\n",
    "data_ma['dfy'] = data_ma['BAA'] - data_ma['AAA']\n",
    "data_ma = data_ma[['yyyymm'] + ma_predictors]\n",
    "data_ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the dataset including all covariates\n",
    "\n",
    "data_ma_long = pd.merge(data_ch['DATE'], data_ma, left_on='DATE', right_on='yyyymm', how='left').drop('yyyymm', axis=1)\n",
    "for cha in chas:\n",
    "    for predictor in ma_predictors:\n",
    "        name = cha + '_' + predictor\n",
    "        data_ch[name] = data_ch[cha] * data_ma_long[predictor]\n",
    "data = data_ch\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "# Training set\n",
    "\n",
    "covariates = [x for x in data.columns if x != 'RET']\n",
    "\n",
    "train_str = '1957-01-31'; train_end = '1974-12-31'\n",
    "data_train = data[(train_str <= data['DATE']) & (data['DATE'] <= train_end)]\n",
    "X_train, y_train = data_train[covariates], data_train[['DATE', 'RET']]\n",
    "print(X_train.shape); print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation set\n",
    "\n",
    "val_str = '1975-01-31'; val_end = '1986-12-31'\n",
    "data_val = data[(val_str <= data['DATE']) & (data['DATE'] <= val_end)]\n",
    "X_val, y_val = data_val[covariates], data_val[['DATE', 'RET']]\n",
    "print(X_val.shape); print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set\n",
    "\n",
    "test_str = '1987-01-31'; test_end = '2016-12-31'\n",
    "data_test = data[(test_str <= data['DATE']) & (data['DATE'] <= test_end)]\n",
    "X_test, y_test = data_test[covariates], data_test[['DATE', 'RET']]\n",
    "print(X_test.shape); print(y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
