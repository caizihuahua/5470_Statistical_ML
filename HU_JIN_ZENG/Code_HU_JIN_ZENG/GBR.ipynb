{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tqdm\n",
    "pd.set_option(\"display.max_columns\",None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('merge_data.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge,ElasticNet\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['permno'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 43\u001b[0m\n\u001b[1;32m     39\u001b[0m testData \u001b[38;5;241m=\u001b[39m data2\u001b[38;5;241m.\u001b[39mloc[testMask]\n\u001b[1;32m     42\u001b[0m trainingData_y \u001b[38;5;241m=\u001b[39m trainingData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexcess_ret\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 43\u001b[0m trainingData_x \u001b[38;5;241m=\u001b[39m \u001b[43mtrainingData\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexcess_ret\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpermno\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myyyymm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m validationData_y \u001b[38;5;241m=\u001b[39m validationData[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexcess_ret\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     46\u001b[0m validationData_x \u001b[38;5;241m=\u001b[39m validationData\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexcess_ret\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpermno\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myyyymm\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.11/site-packages/pandas/core/frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5209\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5346\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.11/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.11/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.11/site-packages/pandas/core/indexes/base.py:7000\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7000\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7001\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['permno'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# GBR Best parameters\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "\n",
    "# store r2_score\n",
    "rList=[]\n",
    "combineList = []\n",
    "\n",
    "#parameters\n",
    "loss_list = ['huber'] #, 'squared_error']\n",
    "learning_rate = [0.01, 0.03, 0.05, 0.1]\n",
    "max_depth = [3,4,5,6]\n",
    "\n",
    "for i in range(30):\n",
    "    df_train = data2[(data2.yyyymm>=195703)&(data2.yyyymm<197503)]\n",
    "    df_validation = data2[(data2.yyyymm>=197503)&(data2.yyyymm<198703)]\n",
    "    df_test = data2[(data2.yyyymm>=198703)&(data2.yyyymm<201603)]\n",
    "\n",
    "    df_train = df_train.copy()\n",
    "    df_validation = df_validation.copy()\n",
    "    df_test = df_test.copy()\n",
    "\n",
    "    trainingstart = 195703\n",
    "    trainingend = 197503 + i*100\n",
    "    validend = trainingend + 1200\n",
    "    testend = validend + 100\n",
    "\n",
    "    trainingMask = (data2.yyyymm >= trainingstart) & (data2.yyyymm< trainingend)\n",
    "    trainingData = data2.loc[trainingMask]\n",
    "    \n",
    "    validationMask = (data2.yyyymm >= trainingend) & (data2.yyyymm< validend)\n",
    "    validationData = data2.loc[validationMask]\n",
    "    \n",
    "    testMask = (data2.yyyymm >= validend) & (data2.yyyymm < testend)\n",
    "    testData = data2.loc[testMask]\n",
    "    \n",
    "    \n",
    "    trainingData_y = trainingData['excess_ret']\n",
    "    trainingData_x = trainingData.drop(['excess_ret','permno', 'yyyymm'], axis=1)\n",
    "    \n",
    "    validationData_y = validationData['excess_ret']\n",
    "    validationData_x = validationData.drop(['excess_ret','permno', 'yyyymm'], axis=1)\n",
    "    \n",
    "    testData_y = testData['excess_ret']\n",
    "    testData_x = testData.drop(['excess_ret','permno', 'yyyymm'], axis =1)\n",
    "    \n",
    "    bestRSqr = float(\"-inf\")\n",
    "    bestGBR = None\n",
    "    bestCombine = None\n",
    "    \n",
    "    for lr in learning_rate:\n",
    "        for max_dep in max_depth:\n",
    "            gbr = GBR(max_depth=max_dep,learning_rate=lr,loss=l)\n",
    "            gbr.fit(X_train,y_train)\n",
    "\n",
    "            pred = gbr.predict(validationData_x)\n",
    "            currentRSqr = r2_score(validationData_y.values, pred)\n",
    "            \n",
    "            if(currentRSqr>bestRSqr):\n",
    "                bestRSqr=currentRSqr\n",
    "                bestGBR=gbr\n",
    "                bestCombine=(learning_rate,max_depth)\n",
    "        \n",
    "    resultPred = bestEnet.predict(testData_x)\n",
    "    resultRSqr = r2_score(testData_y.values, resultPred)\n",
    "    print('result R square for batch',i,': ', resultRSqr, 'best combine:', bestCombine)\n",
    "    rList.append(resultRSqr)\n",
    "    combineList.append(bestCombine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The recursive performance evaluation scheme\n",
    "train_score2=[0]*30\n",
    "validation_score2=[0]*30\n",
    "test_score2=[0]*30\n",
    "scaler=StandardScaler()\n",
    "minmax=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "\n",
    "bestRSqr = float(\"-inf\")\n",
    "bestGBR = None\n",
    "loss_list = ['huber']\n",
    "max_dep = 3\n",
    "lr = 0.01\n",
    "best_year = 0\n",
    "\n",
    "for i in range(0,30):\n",
    "    print('Batch {}:\\nTrain data:1960-{}\\nValuation data:{}-{}\\nTest data:{}-{}'.format(i,1978+i,1978+i,1990+i,1990+i,1991+i))\n",
    "    data_train=data2[(data2.yyyymm>=196001)&(data2.yyyymm<197801+i*100)]\n",
    "    data_validation=data2[(data2.yyyymm>=197801+i*100)&(data2.yyyymm<199001+i*100)]\n",
    "    data_test=data2[(data2.yyyymm>=196001+i*100)&(data2.yyyymm<196101+i*100)]\n",
    "\n",
    "    #Normalize\n",
    "    X_train=data_train.drop(\"excess_ret\",axis=1).copy()\n",
    "    X_train=scaler.fit_transform(X_train)\n",
    "    X_validation=data_validation.drop(\"excess_ret\",axis=1).copy()\n",
    "    X_validation=scaler.transform(X_validation)\n",
    "    X_test=data_test.drop(\"excess_ret\",axis=1).copy()\n",
    "    X_test=scaler.transform(X_test)\n",
    "\n",
    "    y_train=data_train[[\"excess_ret\"]].copy()\n",
    "    y_validation=data_validation[[\"excess_ret\"]].copy()\n",
    "    y_test=data_test[[\"excess_ret\"]].copy()\n",
    "    y_train=scaler.fit_transform(y_train)\n",
    "    y_test=scaler.transform(y_test)\n",
    "    y_validation=scaler.transform(y_validation)\n",
    "    \n",
    "    gbr = GBR(max_depth=3,learning_rate=0.01,loss='huber')\n",
    "    gbr.fit(X_train,y_train)\n",
    "    y_train_pred=gbr.predict(X_train)\n",
    "    train_score2[i]=r2_score(y_train,y_train_pred)\n",
    "    y_validation_pred=gbr.predict(X_validation)\n",
    "    validation_score2[i]=r2_score(y_validation,y_validation_pred)\n",
    "    y_test_pred=gbr.predict(X_test)\n",
    "    test_score2[i]=r2_score(y_test,y_test_pred)\n",
    "    currentRSqr = test_score2[i]\n",
    "\n",
    "    if(currentRSqr>bestRSqr):\n",
    "        bestRSqr=currentRSqr\n",
    "        bestRFR = gbr\n",
    "        best_year = 196001+i*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score =pd.DataFrame(test_score2)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performence of GBR+H\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"GBR Performance\")\n",
    "year=np.arange(1990,2020)\n",
    "plt.plot(year,test_score2)\n",
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"score--R-square\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Importance \n",
    "#X_test0 = best_data1.drop(best_data1.columns[0],axis=1,inplace=True).copy()\n",
    "\n",
    "X_test0 = data2[(data2.yyyymm>=best_year)&(data2.yyyymm<best_year+100)]\n",
    "print(X_test0.shape)\n",
    "a = X_test0.drop(\"excess_ret\",axis=1).copy()\n",
    "print(a.shape)\n",
    "id = a.columns\n",
    "L = len(a.columns)\n",
    "train_score=[0]*L\n",
    "validation_score=[0]*L\n",
    "test_score2 = [0]*L\n",
    "importance_GBR_H=[0]*L\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable importance\n",
    "\n",
    "for i in range(0,L):\n",
    "    \n",
    "    X_test = X_test0.drop(\"excess_ret\",axis=1).copy()\n",
    "    X_test.loc[:,id[i]]=0\n",
    "    X_test=scaler.fit_transform(X_test)\n",
    "\n",
    "    y_test=X_test0[[\"excess_ret\"]].copy()\n",
    "    y_test=scaler.fit_transform(y_test)\n",
    "    \n",
    "\n",
    "    y_test_pred=bestRFR.predict(X_test)\n",
    "    test_score2[i] = r2_score(y_test,y_test_pred)\n",
    "    importance_GBR_H[i] = bestRSqr - test_score2[i]\n",
    "\n",
    "    \n",
    "    del X_test,y_test,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_GBR_H = np.abs(importance_GBR_H)\n",
    "importance_GBR_H1 = pd.DataFrame(importance_GBR_H,columns=['Importance'], index=id)\n",
    "importance_GBR_H1 = importance_GBR_H1.sort_values(by='Importance',ascending=True)\n",
    "importance_GBR_H1 = importance_GBR_H1.tail(20)\n",
    "importance_GBR_H1.plot(kind='barh', figsize=(9, 7))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
